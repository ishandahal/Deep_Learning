{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mnist_data_unzip.ipynb","provenance":[],"mount_file_id":"11bWdXwspgkNyieUJOD1HXh_Uit5ZOFqB","authorship_tag":"ABX9TyM422X4lxNlEPQhRqtKO6VR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9xnO0o3FdvLn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596946396390,"user_tz":240,"elapsed":25395,"user":{"displayName":"Ishan Dahal","photoUrl":"","userId":"15881968045115932085"}}},"source":["from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","\n","\n","X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n","y = y.astype(int)\n","X = ((X / 255.) - .5) * 2\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=10000, random_state=123, stratify=y)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQiTQc5nYCus","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596946360375,"user_tz":240,"elapsed":508,"user":{"displayName":"Ishan Dahal","photoUrl":"","userId":"15881968045115932085"}}},"source":["import numpy as np\n","import sys\n","\n","\n","class NeuralNetMLP(object):\n","    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n","\n","    Parameters\n","    ------------\n","    n_hidden : int (default: 30)\n","        Number of hidden units.\n","    l2 : float (default: 0.)\n","        Lambda value for L2-regularization.\n","        No regularization if l2=0. (default)\n","    epochs : int (default: 100)\n","        Number of passes over the training set.\n","    eta : float (default: 0.001)\n","        Learning rate.\n","    shuffle : bool (default: True)\n","        Shuffles training data every epoch if True to prevent circles.\n","    minibatch_size : int (default: 1)\n","        Number of training examples per minibatch.\n","    seed : int (default: None)\n","        Random seed for initializing weights and shuffling.\n","\n","    Attributes\n","    -----------\n","    eval_ : dict\n","      Dictionary collecting the cost, training accuracy,\n","      and validation accuracy for each epoch during training.\n","\n","    \"\"\"\n","    def __init__(self, n_hidden=30,\n","                 l2=0., epochs=100, eta=0.001,\n","                 shuffle=True, minibatch_size=1, seed=None):\n","\n","        self.random = np.random.RandomState(seed)\n","        self.n_hidden = n_hidden\n","        self.l2 = l2\n","        self.epochs = epochs\n","        self.eta = eta\n","        self.shuffle = shuffle\n","        self.minibatch_size = minibatch_size\n","\n","    def _onehot(self, y, n_classes):\n","        \"\"\"Encode labels into one-hot representation\n","\n","        Parameters\n","        ------------\n","        y : array, shape = [n_examples]\n","            Target values.\n","        n_classes : int\n","            Number of classes\n","\n","        Returns\n","        -----------\n","        onehot : array, shape = (n_examples, n_labels)\n","\n","        \"\"\"\n","        onehot = np.zeros((n_classes, y.shape[0]))\n","        for idx, val in enumerate(y.astype(int)):\n","            onehot[val, idx] = 1.\n","        return onehot.T\n","\n","    def _sigmoid(self, z):\n","        \"\"\"Compute logistic function (sigmoid)\"\"\"\n","        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n","\n","    def _forward(self, X):\n","        \"\"\"Compute forward propagation step\"\"\"\n","\n","        # step 1: net input of hidden layer\n","        # [n_examples, n_features] dot [n_features, n_hidden]\n","        # -> [n_examples, n_hidden]\n","        z_h = np.dot(X, self.w_h) + self.b_h\n","\n","        # step 2: activation of hidden layer\n","        a_h = self._sigmoid(z_h)\n","\n","        # step 3: net input of output layer\n","        # [n_examples, n_hidden] dot [n_hidden, n_classlabels]\n","        # -> [n_examples, n_classlabels]\n","\n","        z_out = np.dot(a_h, self.w_out) + self.b_out\n","\n","        # step 4: activation output layer\n","        a_out = self._sigmoid(z_out)\n","\n","        return z_h, a_h, z_out, a_out\n","\n","    def _compute_cost(self, y_enc, output):\n","        \"\"\"Compute cost function.\n","\n","        Parameters\n","        ----------\n","        y_enc : array, shape = (n_examples, n_labels)\n","            one-hot encoded class labels.\n","        output : array, shape = [n_examples, n_output_units]\n","            Activation of the output layer (forward propagation)\n","\n","        Returns\n","        ---------\n","        cost : float\n","            Regularized cost\n","\n","        \"\"\"\n","        L2_term = (self.l2 *\n","                   (np.sum(self.w_h ** 2.) +\n","                    np.sum(self.w_out ** 2.)))\n","\n","        term1 = -y_enc * (np.log(output))\n","        term2 = (1. - y_enc) * np.log(1. - output)\n","        cost = np.sum(term1 - term2) + L2_term\n","        \n","        # If you are applying this cost function to other\n","        # datasets where activation\n","        # values maybe become more extreme (closer to zero or 1)\n","        # you may encounter \"ZeroDivisionError\"s due to numerical\n","        # instabilities in Python & NumPy for the current implementation.\n","        # I.e., the code tries to evaluate log(0), which is undefined.\n","        # To address this issue, you could add a small constant to the\n","        # activation values that are passed to the log function.\n","        #\n","        # For example:\n","        #\n","        # term1 = -y_enc * (np.log(output + 1e-5))\n","        # term2 = (1. - y_enc) * np.log(1. - output + 1e-5)\n","        \n","        return cost\n","\n","    def predict(self, X):\n","        \"\"\"Predict class labels\n","\n","        Parameters\n","        -----------\n","        X : array, shape = [n_examples, n_features]\n","            Input layer with original features.\n","\n","        Returns:\n","        ----------\n","        y_pred : array, shape = [n_examples]\n","            Predicted class labels.\n","\n","        \"\"\"\n","        z_h, a_h, z_out, a_out = self._forward(X)\n","        y_pred = np.argmax(z_out, axis=1)\n","        return y_pred\n","\n","    def fit(self, X_train, y_train, X_valid, y_valid):\n","        \"\"\" Learn weights from training data.\n","\n","        Parameters\n","        -----------\n","        X_train : array, shape = [n_examples, n_features]\n","            Input layer with original features.\n","        y_train : array, shape = [n_examples]\n","            Target class labels.\n","        X_valid : array, shape = [n_examples, n_features]\n","            Sample features for validation during training\n","        y_valid : array, shape = [n_examples]\n","            Sample labels for validation during training\n","\n","        Returns:\n","        ----------\n","        self\n","\n","        \"\"\"\n","        n_output = np.unique(y_train).shape[0]  # number of class labels\n","        n_features = X_train.shape[1]\n","\n","        ########################\n","        # Weight initialization\n","        ########################\n","\n","        # weights for input -> hidden\n","        self.b_h = np.zeros(self.n_hidden)\n","        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n","                                      size=(n_features, self.n_hidden))\n","\n","        # weights for hidden -> output\n","        self.b_out = np.zeros(n_output)\n","        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n","                                        size=(self.n_hidden, n_output))\n","\n","        epoch_strlen = len(str(self.epochs))  # for progress formatting\n","        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n","\n","        y_train_enc = self._onehot(y_train, n_output)\n","\n","        # iterate over training epochs\n","        for i in range(self.epochs):\n","\n","            # iterate over minibatches\n","            indices = np.arange(X_train.shape[0])\n","\n","            if self.shuffle:\n","                self.random.shuffle(indices)\n","\n","            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n","                                   1, self.minibatch_size):\n","                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n","\n","                # forward propagation\n","                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n","\n","                ##################\n","                # Backpropagation\n","                ##################\n","\n","                # [n_examples, n_classlabels]\n","                delta_out = a_out - y_train_enc[batch_idx]\n","\n","                # [n_examples, n_hidden]\n","                sigmoid_derivative_h = a_h * (1. - a_h)\n","\n","                # [n_examples, n_classlabels] dot [n_classlabels, n_hidden]\n","                # -> [n_examples, n_hidden]\n","                delta_h = (np.dot(delta_out, self.w_out.T) *\n","                           sigmoid_derivative_h)\n","\n","                # [n_features, n_examples] dot [n_examples, n_hidden]\n","                # -> [n_features, n_hidden]\n","                grad_w_h = np.dot(X_train[batch_idx].T, delta_h)\n","                grad_b_h = np.sum(delta_h, axis=0)\n","\n","                # [n_hidden, n_examples] dot [n_examples, n_classlabels]\n","                # -> [n_hidden, n_classlabels]\n","                grad_w_out = np.dot(a_h.T, delta_out)\n","                grad_b_out = np.sum(delta_out, axis=0)\n","\n","                # Regularization and weight updates\n","                delta_w_h = (grad_w_h + self.l2*self.w_h)\n","                delta_b_h = grad_b_h # bias is not regularized\n","                self.w_h -= self.eta * delta_w_h\n","                self.b_h -= self.eta * delta_b_h\n","\n","                delta_w_out = (grad_w_out + self.l2*self.w_out)\n","                delta_b_out = grad_b_out  # bias is not regularized\n","                self.w_out -= self.eta * delta_w_out\n","                self.b_out -= self.eta * delta_b_out\n","\n","            #############\n","            # Evaluation\n","            #############\n","\n","            # Evaluation after each epoch during training\n","            z_h, a_h, z_out, a_out = self._forward(X_train)\n","            \n","            cost = self._compute_cost(y_enc=y_train_enc,\n","                                      output=a_out)\n","\n","            y_train_pred = self.predict(X_train)\n","            y_valid_pred = self.predict(X_valid)\n","\n","            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n","                         X_train.shape[0])\n","            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n","                         X_valid.shape[0])\n","\n","            sys.stderr.write('\\r%0*d/%d | Cost: %.2f '\n","                             '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n","                             (epoch_strlen, i+1, self.epochs, cost,\n","                              train_acc*100, valid_acc*100))\n","            sys.stderr.flush()\n","\n","            self.eval_['cost'].append(cost)\n","            self.eval_['train_acc'].append(train_acc)\n","            self.eval_['valid_acc'].append(valid_acc)\n","\n","        return self"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CK8x9v7BYcTo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"status":"error","timestamp":1596946608573,"user_tz":240,"elapsed":200002,"user":{"displayName":"Ishan Dahal","photoUrl":"","userId":"15881968045115932085"}},"outputId":"c634eb09-046e-47f3-f86b-3202fa15a90f"},"source":["n_epochs = 200\n","nn = NeuralNetMLP(n_hidden=100, \n","                  l2=0.01, \n","                  epochs=n_epochs, \n","                  eta=0.0005,\n","                  minibatch_size=100, \n","                  shuffle=True,\n","                  seed=1)\n","\n","nn.fit(X_train=X_train[:55000], \n","       y_train=y_train[:55000],\n","       X_valid=X_train[55000:],\n","       y_valid=y_train[55000:])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["074/200 | Cost: 9316.58 | Train/Valid Acc.: 98.01%/96.62% "],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a44b6cb76148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m        \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m55000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m        \u001b[0mX_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m55000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m        y_valid=y_train[55000:])\n\u001b[0m","\u001b[0;32m<ipython-input-2-d1456d3ec5e5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# Evaluation after each epoch during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mz_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             cost = self._compute_cost(y_enc=y_train_enc,\n","\u001b[0;32m<ipython-input-2-d1456d3ec5e5>\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# [n_examples, n_features] dot [n_features, n_hidden]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# -> [n_examples, n_hidden]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mz_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_h\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# step 2: activation of hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vUYI-3SvYrc_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1596946355711,"user_tz":240,"elapsed":452,"user":{"displayName":"Ishan Dahal","photoUrl":"","userId":"15881968045115932085"}},"outputId":"d413c521-06e9-4150-bc7a-26dfea33ad3f"},"source":["import matplotlib.pyplot as plt\n","\n","\n","plt.plot(range(nn.epochs), nn.eval_['cost'])\n","plt.ylabel('Cost')\n","plt.xlabel('Epochs')\n","#plt.savefig('images/12_07.png', dpi=300)\n","plt.show()"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2bca8dec17e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"code","metadata":{"id":"4inbTG24avo9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}
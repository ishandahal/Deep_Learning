{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch_Barebones_Api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhs2tcTNv2omZPQDB0J2jM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishandahal/Repo_Torch/blob/master/Torch_Barebones_Api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRxERavNMWc8",
        "colab_type": "text"
      },
      "source": [
        "##Testing different level APIs of Torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbjlj0PR2xXP",
        "colab_type": "text"
      },
      "source": [
        "##Getting required packages for the data to be utilized (CIFAR10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVV6vsK-2c1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "d896c573-12dd-42ac-dc5f-ca72dd9e1d24"
      },
      "source": [
        "!pip install git+https://github.com/deepvision-class/starter-code"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/deepvision-class/starter-code\n",
            "  Cloning https://github.com/deepvision-class/starter-code to /tmp/pip-req-build-jv8hth0x\n",
            "  Running command git clone -q https://github.com/deepvision-class/starter-code /tmp/pip-req-build-jv8hth0x\n",
            "Requirement already satisfied (use --upgrade to upgrade): Colab-Utils==0.1.dev0 from git+https://github.com/deepvision-class/starter-code in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (from Colab-Utils==0.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (1.7.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (0.4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (4.6)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (0.2.8)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (49.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (4.1.1)\n",
            "Building wheels for collected packages: Colab-Utils\n",
            "  Building wheel for Colab-Utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Colab-Utils: filename=Colab_Utils-0.1.dev0-cp36-none-any.whl size=10323 sha256=5a020457fdd7f1a96fd809c3d8be9e8f3992d202a95af5ef49a7338129cc847e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l0_zl6qy/wheels/63/d1/27/a208931527abb98d326d00209f46c80c9d745851d6a1defd10\n",
            "Successfully built Colab-Utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy2gAAW828oY",
        "colab_type": "text"
      },
      "source": [
        "##Setup code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DmdppgV2qxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import coutils\n",
        "from coutils import fix_random_seed\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwNYydP44Myy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "547efc72-ec67-46d2-d8f8-c32611efe0d8"
      },
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "# The torchvision.transforms package provides tools for preprocessing data\n",
        "# and for performing data augmentation; here we set up a transform to\n",
        "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
        "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
        "# training set into train and val sets by passing a Sampler object to the\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\n",
        "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
        "                            transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku_RhUzL4ZY_",
        "colab_type": "text"
      },
      "source": [
        "## If GPU is available, it will be used if not fall back is on CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIFy9d264TSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10c82b60-571d-4540-b861-c44bc29f4a01"
      },
      "source": [
        "dtype = torch.float32\n",
        "ltype = torch.long\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "print('using device:', device)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYk9qfov4jWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Defining flatten function for convenience\n",
        "def flatten(x, start_dim=1, end_dim=-1):\n",
        "  return x.flatten(start_dim=start_dim, end_dim=end_dim)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuvlqWZf8lLx",
        "colab_type": "text"
      },
      "source": [
        "## Barebones PyTorch for a two layered network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_F3o1Py5-Pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad682245-4c35-485e-a1df-c697d5a139ec"
      },
      "source": [
        "def two_layer_fc(x, params):\n",
        "  \"\"\"\n",
        "  A fully-connected neural networks; the architecture is:\n",
        "  NN is fully connected -> ReLU -> fully connected layer.\n",
        "  Note that this function only defines the forward pass; \n",
        "  PyTorch will take care of the backward pass for us.\n",
        "  \n",
        "  The input to the network will be a minibatch of data, of shape\n",
        "  (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n",
        "  and the output layer will produce scores for C classes.\n",
        "  \n",
        "  Inputs:\n",
        "  - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
        "    input data.\n",
        "  - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n",
        "    w1 has shape (H, D) and w2 has shape (C, H).\n",
        "  \n",
        "  Returns:\n",
        "  - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n",
        "    the input data x.\n",
        "  \"\"\"\n",
        "  # first we flatten the image\n",
        "  x = flatten(x)  # shape: [batch_size, C x H x W]\n",
        "  \n",
        "  w1, b1, w2, b2 = params\n",
        "  \n",
        "  # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
        "  # w2 have requires_grad=True, operations involving these Tensors will cause\n",
        "  # PyTorch to build a computational graph, allowing automatic computation of\n",
        "  # gradients. Since we are no longer implementing the backward pass by hand we\n",
        "  # don't need to keep references to intermediate values.\n",
        "  # Note that F.linear(x, w, b) is equivalent to x.mm(w.t()) + b\n",
        "  # For ReLU, you can also use `.clamp(min=0)`, equivalent to `F.relu()`\n",
        "\n",
        "  x = F.relu(F.linear(x, w1, b1))\n",
        "  x = F.linear(x, w2, b2)\n",
        "  return x\n",
        "    \n",
        "\n",
        "def two_layer_fc_test():\n",
        "  hidden_layer_size = 42\n",
        "  x = torch.zeros((64, 3, 16, 16), dtype=dtype)  # minibatch size 64, feature dimension 3*16*16\n",
        "  w1 = torch.zeros((hidden_layer_size, 3*16*16), dtype=dtype)\n",
        "  b1 = torch.zeros((hidden_layer_size,), dtype=dtype)\n",
        "  w2 = torch.zeros((10, hidden_layer_size), dtype=dtype)\n",
        "  b2 = torch.zeros((10,), dtype=dtype)\n",
        "  scores = two_layer_fc(x, [w1, b1, w2, b2])\n",
        "  print('Output size:', list(scores.size()))  # you should see [64, 10]\n",
        "\n",
        "two_layer_fc_test()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size: [64, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDyPVGaXA0_J",
        "colab_type": "text"
      },
      "source": [
        "#Barebones three layered Conv-net."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRYLV2Uh_TQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def three_layer_convnet(x, params):\n",
        "  \"\"\"\n",
        "  Performs the forward pass of a three-layer convolutional network with the\n",
        "  architecture defined above.\n",
        "\n",
        "  Inputs:\n",
        "  - x: A PyTorch Tensor of shape (N, C, H, W) giving a minibatch of images\n",
        "  - params: A list of PyTorch Tensors giving the weights and biases for the\n",
        "    network; should contain the following:\n",
        "    - conv_w1: PyTorch Tensor of shape (channel_1, C, KH1, KW1) giving weights\n",
        "      for the first convolutional layer\n",
        "    - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n",
        "      convolutional layer\n",
        "    - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n",
        "      weights for the second convolutional layer\n",
        "    - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n",
        "      convolutional layer\n",
        "    - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n",
        "      figure out what the shape should be?\n",
        "    - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n",
        "      figure out what the shape should be?\n",
        "  \n",
        "  Returns:\n",
        "  - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n",
        "  \"\"\"\n",
        "  conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
        "  scores = None\n",
        "  \n",
        "  x = F.relu(F.conv2d(x, conv_w1, bias=conv_b1, padding=2))\n",
        "  x = F.relu(F.conv2d(x, conv_w2, bias=conv_b2, padding=1))\n",
        "  x = flatten(x)\n",
        "  scores = F.linear(x, fc_w, fc_b) ##shape of w = C, ch_2*32*32, b=C\n",
        "\n",
        "  return scores"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmHtkGC-F61A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "862c4d34-4fcf-4899-f12c-b1784372f728"
      },
      "source": [
        "def three_layer_convnet_test():\n",
        "  x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "\n",
        "  conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
        "  conv_b1 = torch.zeros((6,))  # out_channel\n",
        "  conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
        "  conv_b2 = torch.zeros((9,))  # out_channel\n",
        "\n",
        "  # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
        "  fc_w = torch.zeros((10, 9 * 32 * 32))\n",
        "  fc_b = torch.zeros(10)\n",
        "\n",
        "  scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
        "  print('Output size:', list(scores.size()))  # you should see [64, 10]\n",
        "three_layer_convnet_test()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size: [64, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnfGtSTILt1L",
        "colab_type": "text"
      },
      "source": [
        "##Kaiming Initialization \n",
        "Using Kaiming initialization for the weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCA-pQVAF_CK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "06ed760d-0cc8-4867-87dc-431dcb72b982"
      },
      "source": [
        "fix_random_seed(0)\n",
        "\n",
        "# Create a weight of shape [3 x 5]\n",
        "print(nn.init.kaiming_normal_(torch.empty(3, 5, dtype=dtype, device=device)))\n",
        "print(nn.init.zeros_(torch.empty(3, 5, dtype=dtype, device=device)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5848, -0.2690, -1.6721,  0.0918, -0.0764],\n",
            "        [-0.3667, -0.3939, -0.2077, -0.6796, -0.2297],\n",
            "        [-1.0569,  1.4328,  0.1971, -0.1165,  0.8137]], device='cuda:0')\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XWlMXx-NWKY",
        "colab_type": "text"
      },
      "source": [
        "###Method to check the accuracy of our models.\n",
        "Note: Whenc checking for accuracy gradients do not need to be calculated. In order to prevent the computational graph from being built we specify `torch.no_grad()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTquibrENC7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy_part2(loader, model_fn, params):\n",
        "  \"\"\"\n",
        "  Check the accuracy of a classification model.\n",
        "  \n",
        "  Inputs:\n",
        "  - loader: A DataLoader for the data split we want to check\n",
        "  - model_fn: A function that performs the forward pass of the model,\n",
        "    with the signature scores = model_fn(x, params)\n",
        "  - params: List of PyTorch Tensors giving parameters of the model\n",
        "  \n",
        "  Returns: Nothing, but prints the accuracy of the model\n",
        "  \"\"\"\n",
        "  split = 'val' if loader.dataset.train else 'test'\n",
        "  print('Checking accuracy on the %s set' % split)\n",
        "  num_correct, num_samples = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=ltype)\n",
        "      scores = model_fn(x, params)\n",
        "      _, preds = scores.max(1)\n",
        "      num_correct += (preds == y).sum()\n",
        "      num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D9SfI5LO6Jk",
        "colab_type": "text"
      },
      "source": [
        "###Barebones Pytorch: Training loop\n",
        "Basic training loop using stocastic gradiant descent wothout momentum. We will use `torch.nn.functional.cross_entropy` to compute the loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArqyBwGyOwCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_part2(model_fn, params, learning_rate):\n",
        "  \"\"\"\n",
        "  Train a model on CIFAR-10.\n",
        "  \n",
        "  Inputs:\n",
        "  - model_fn: A Python function that performs the forward pass of the model.\n",
        "    It should have the signature scores = model_fn(x, params) where x is a\n",
        "    PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
        "    model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
        "    scores for the elements in x.\n",
        "  - params: List of PyTorch Tensors giving weights for the model\n",
        "  - learning_rate: Python scalar giving the learning rate to use for SGD\n",
        "  \n",
        "  Returns: Nothing\n",
        "  \"\"\"\n",
        "  for t, (x, y) in enumerate(loader_train):\n",
        "    # Move the data to the proper device (GPU or CPU)\n",
        "    x = x.to(device=device, dtype=dtype)\n",
        "    y = y.to(device=device, dtype=ltype)\n",
        "\n",
        "    # Forward pass: compute scores and loss\n",
        "    scores = model_fn(x, params)\n",
        "    loss = F.cross_entropy(scores, y)\n",
        "\n",
        "    # Backward pass: PyTorch figures out which Tensors in the computational\n",
        "    # graph has requires_grad=True and uses backpropagation to compute the\n",
        "    # gradient of the loss with respect to these Tensors, and stores the\n",
        "    # gradients in the .grad attribute of each Tensor.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters. We don't want to backpropagate through the\n",
        "    # parameter updates, so we scope the updates under a torch.no_grad()\n",
        "    # context manager to prevent a computational graph from being built.\n",
        "    with torch.no_grad():\n",
        "      for w in params:\n",
        "        if w.requires_grad:\n",
        "          w -= learning_rate * w.grad\n",
        "\n",
        "          # Manually zero the gradients after running the backward pass\n",
        "          w.grad.zero_()\n",
        "\n",
        "    if t % print_every == 0 or t == len(loader_train)-1:\n",
        "      print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "      check_accuracy_part2(loader_val, model_fn, params)\n",
        "      print()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCGlf8QocD7N",
        "colab_type": "text"
      },
      "source": [
        "###Training a twolayered fully connected NN.\n",
        "Each mini-batch has shape `[64, 3, 32, 32]`. \n",
        "After flattening the shape of input will be `[64, 3 * 32 * 32]`. \n",
        "The output will be `[64, 10]`. This is because there are 10 classes. Each row is the probability distribution of the input over the 10 classes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCIV57xnRGjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "fe280aed-a52d-4a7f-c77c-3a5432b65752"
      },
      "source": [
        "fix_random_seed(0)\n",
        "\n",
        "C, H, W = 3, 32, 32\n",
        "num_classes = 10\n",
        "\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "\n",
        "w1 = nn.init.kaiming_normal_(torch.empty(hidden_layer_size, C*H*W, dtype=dtype, device=device))\n",
        "w1.requires_grad = True\n",
        "b1 = nn.init.zeros_(torch.empty(hidden_layer_size, dtype=dtype, device=device))\n",
        "b1.requires_grad = True\n",
        "w2 = nn.init.kaiming_normal_(torch.empty(num_classes, hidden_layer_size, dtype=dtype, device=device))\n",
        "w2.requires_grad = True\n",
        "b2 = nn.init.zeros_(torch.empty(num_classes, dtype=dtype, device=device))\n",
        "b2.requires_grad = True\n",
        "\n",
        "train_part2(two_layer_fc, [w1, b1, w2, b2], learning_rate=learning_rate)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 3.5134\n",
            "Checking accuracy on the val set\n",
            "Got 153 / 1000 correct (15.30%)\n",
            "\n",
            "Iteration 100, loss = 2.8268\n",
            "Checking accuracy on the val set\n",
            "Got 363 / 1000 correct (36.30%)\n",
            "\n",
            "Iteration 200, loss = 2.1683\n",
            "Checking accuracy on the val set\n",
            "Got 396 / 1000 correct (39.60%)\n",
            "\n",
            "Iteration 300, loss = 1.8409\n",
            "Checking accuracy on the val set\n",
            "Got 419 / 1000 correct (41.90%)\n",
            "\n",
            "Iteration 400, loss = 1.5695\n",
            "Checking accuracy on the val set\n",
            "Got 430 / 1000 correct (43.00%)\n",
            "\n",
            "Iteration 500, loss = 2.1471\n",
            "Checking accuracy on the val set\n",
            "Got 414 / 1000 correct (41.40%)\n",
            "\n",
            "Iteration 600, loss = 1.9083\n",
            "Checking accuracy on the val set\n",
            "Got 404 / 1000 correct (40.40%)\n",
            "\n",
            "Iteration 700, loss = 1.8546\n",
            "Checking accuracy on the val set\n",
            "Got 422 / 1000 correct (42.20%)\n",
            "\n",
            "Iteration 765, loss = 1.5771\n",
            "Checking accuracy on the val set\n",
            "Got 397 / 1000 correct (39.70%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scQa-feViC5U",
        "colab_type": "text"
      },
      "source": [
        "###Barebones: Training a ConvNet\n",
        "In the three layered NN, we are using: \n",
        "\n",
        "1. Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2 \n",
        "2. ReLU\n",
        "3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n",
        "4. ReLU\n",
        "5. Fully-connected layer (with bias) to compute scores for 10 classes\n",
        "\n",
        "Initializing weights using random_weights and biases as zeros. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL97WoZXjb8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "9e34f9e5-7e73-4ba0-bd9d-6b9d04d27d4b"
      },
      "source": [
        "fix_random_seed(0)\n",
        "\n",
        "C, H, W = 3, 32, 32\n",
        "num_classes = 10\n",
        "\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "kernel_size_1 = 5\n",
        "kernel_size_2 = 3\n",
        "\n",
        "learning_rate = 3e-3\n",
        "\n",
        "conv_w1 = None\n",
        "conv_b1 = None\n",
        "conv_w2 = None\n",
        "conv_b2 = None\n",
        "fc_w = None\n",
        "fc_b = None\n",
        "\n",
        "\n",
        "# Replace \"pass\" statement with your code\n",
        "conv_w1 = nn.init.kaiming_normal_(torch.empty(channel_1, C, kernel_size_1, kernel_size_1,\n",
        "                                              dtype=dtype, device=device))\n",
        "conv_w1.requires_grad=True\n",
        "conv_b1 = nn.init.zeros_(torch.empty(channel_1, dtype=dtype, device=device))\n",
        "conv_w2 = nn.init.kaiming_normal_(torch.empty(channel_2, channel_1, kernel_size_2, kernel_size_2,\n",
        "                                              dtype=dtype, device=device))\n",
        "conv_w2.requires_grad=True\n",
        "conv_b2 = nn.init.zeros_(torch.empty(channel_2, dtype=dtype, device=device))\n",
        "conv_b2.requires_grad=True\n",
        "fc_w = nn.init.kaiming_normal_(torch.empty(num_classes, channel_2 * H * W,\n",
        "                                           dtype=dtype, device=device))\n",
        "fc_w.requires_grad=True\n",
        "fc_b = nn.init.zeros_(torch.empty(num_classes, dtype=dtype, device=device))\n",
        "fc_b.requires_grad=True\n",
        "\n",
        "\n",
        "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
        "train_part2(three_layer_convnet, params, learning_rate)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 2.6007\n",
            "Checking accuracy on the val set\n",
            "Got 109 / 1000 correct (10.90%)\n",
            "\n",
            "Iteration 100, loss = 1.9976\n",
            "Checking accuracy on the val set\n",
            "Got 349 / 1000 correct (34.90%)\n",
            "\n",
            "Iteration 200, loss = 1.7895\n",
            "Checking accuracy on the val set\n",
            "Got 392 / 1000 correct (39.20%)\n",
            "\n",
            "Iteration 300, loss = 1.6618\n",
            "Checking accuracy on the val set\n",
            "Got 417 / 1000 correct (41.70%)\n",
            "\n",
            "Iteration 400, loss = 1.5938\n",
            "Checking accuracy on the val set\n",
            "Got 449 / 1000 correct (44.90%)\n",
            "\n",
            "Iteration 500, loss = 1.6665\n",
            "Checking accuracy on the val set\n",
            "Got 447 / 1000 correct (44.70%)\n",
            "\n",
            "Iteration 600, loss = 1.6319\n",
            "Checking accuracy on the val set\n",
            "Got 468 / 1000 correct (46.80%)\n",
            "\n",
            "Iteration 700, loss = 1.7866\n",
            "Checking accuracy on the val set\n",
            "Got 484 / 1000 correct (48.40%)\n",
            "\n",
            "Iteration 765, loss = 1.2447\n",
            "Checking accuracy on the val set\n",
            "Got 460 / 1000 correct (46.00%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoH2GL8YDh36",
        "colab_type": "text"
      },
      "source": [
        "###Modular Apis.\n",
        "2 layered fully connected network with kaiming normal for weights and kaiming zeros for bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9xtJ6hRDhd8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6cc7f8f5-d389-43ef-a233-99594ca13c73"
      },
      "source": [
        "class TwoLayerFC(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        # assign layer objects to class attributes\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "        nn.init.kaiming_normal_(self.fc2.weight)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward always defines connectivity\n",
        "        x = flatten(x)\n",
        "        scores = self.fc2(F.relu(self.fc1(x)))\n",
        "        return scores\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "  input_size = 3*16*16\n",
        "  x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 3*16*16\n",
        "  model = TwoLayerFC(input_size, 42, 10)\n",
        "  scores = model(x)\n",
        "  print('Architecture:')\n",
        "  print(model) # printing `nn.Module` shows the architecture of the module.\n",
        "  print('Output size:', list(scores.size()))  # you should see [64, 10]\n",
        "test_TwoLayerFC()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:\n",
            "TwoLayerFC(\n",
            "  (fc1): Linear(in_features=768, out_features=42, bias=True)\n",
            "  (fc2): Linear(in_features=42, out_features=10, bias=True)\n",
            ")\n",
            "Output size: [64, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvDlHDJhSKpM",
        "colab_type": "text"
      },
      "source": [
        "###Modular Apis.\n",
        "Creating a three layered ConvNet.\n",
        "1. Convolutional layer with `channel_1` 5x5 filters with zero-padding of 2\n",
        "2. ReLU\n",
        "3. Convolutional layer with `channel_2` 3x3 filters with zero-padding of 1\n",
        "4. ReLU\n",
        "5. Fully-connected layer to `num_classes` classes\n",
        "\n",
        "Using Kaiming initialization for the weights and zeros for the biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA1uwgkSSmFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "217e56c2-1a00-47e0-fc3f-61305ea9413d"
      },
      "source": [
        "class ThreeLayerConvNet(nn.Module):\n",
        "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(channel_2*H*W, num_classes)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "        nn.init.zeros_(self.conv1.bias)\n",
        "        nn.init.zeros_(self.conv2.bias)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        scores = None\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = flatten(x)\n",
        "        scores = self.fc1(x)\n",
        "        return scores\n",
        "\n",
        "def test_ThreeLayerConvNet():\n",
        "  x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "  model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
        "  scores = model(x)\n",
        "  print(model) # printing `nn.Module` shows the architecture of the module.\n",
        "  print('Output size:', list(scores.size()))  # you should see [64, 10]\n",
        "test_ThreeLayerConvNet()\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ThreeLayerConvNet(\n",
            "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(12, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=8192, out_features=10, bias=True)\n",
            ")\n",
            "Output size: [64, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8hcihsBbfeD",
        "colab_type": "text"
      },
      "source": [
        "###Checking the accuracy of the modular Conv Net\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayhgi6WESIUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy_part34(loader, model):\n",
        "  if loader.dataset.train:\n",
        "    print('Checking accuracy on validation set')\n",
        "  else:\n",
        "    print('Checking accuracy on test set')   \n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()  # set model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=ltype)\n",
        "      scores = model(x)\n",
        "      _, preds = scores.max(1)\n",
        "      num_correct += (preds == y).sum()\n",
        "      num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "  return acc"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXd2duIyb6Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(optimizer, lrd, epoch, schedule):\n",
        "  \"\"\"\n",
        "  Multiply lrd to the learning rate if epoch is in schedule\n",
        "  \n",
        "  Inputs:\n",
        "  - optimizer: An Optimizer object we will use to train the model\n",
        "  - lrd: learning rate decay; a factor multiplied at scheduled epochs\n",
        "  - epochs: the current epoch number\n",
        "  - schedule: the list of epochs that requires learning rate update\n",
        "  \n",
        "  Returns: Nothing, but learning rate might be updated\n",
        "  \"\"\"\n",
        "  if epoch in schedule:\n",
        "    for param_group in optimizer.param_groups:\n",
        "      print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\n",
        "      param_group['lr'] *= lrd\n",
        "\n",
        "def train_part345(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[], verbose=True):\n",
        "  \"\"\"\n",
        "  Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "  \n",
        "  Inputs:\n",
        "  - model: A PyTorch Module giving the model to train.\n",
        "  - optimizer: An Optimizer object we will use to train the model\n",
        "  - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "  \n",
        "  Returns: Nothing, but prints model accuracies during training.\n",
        "  \"\"\"\n",
        "  model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "  num_iters = epochs * len(loader_train)\n",
        "  if verbose:\n",
        "    num_prints = num_iters // print_every + 1\n",
        "  else:\n",
        "    num_prints = epochs\n",
        "  acc_history = torch.zeros(num_prints, dtype=torch.float)\n",
        "  iter_history = torch.zeros(num_prints, dtype=torch.long)\n",
        "  for e in range(epochs):\n",
        "    \n",
        "    adjust_learning_rate(optimizer, learning_rate_decay, e, schedule)\n",
        "    \n",
        "    for t, (x, y) in enumerate(loader_train):\n",
        "      model.train()  # put model to training mode\n",
        "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=ltype)\n",
        "\n",
        "      scores = model(x)\n",
        "      loss = F.cross_entropy(scores, y)\n",
        "\n",
        "      # Zero out all of the gradients for the variables which the optimizer\n",
        "      # will update.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # This is the backwards pass: compute the gradient of the loss with\n",
        "      # respect to each  parameter of the model.\n",
        "      loss.backward()\n",
        "\n",
        "      # Actually update the parameters of the model using the gradients\n",
        "      # computed by the backwards pass.\n",
        "      optimizer.step()\n",
        "\n",
        "      tt = t + e * len(loader_train)\n",
        "\n",
        "      if verbose and (tt % print_every == 0 or (e == epochs-1 and t == len(loader_train)-1)):\n",
        "        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n",
        "        acc = check_accuracy_part34(loader_val, model)\n",
        "        acc_history[tt // print_every] = acc\n",
        "        iter_history[tt // print_every] = tt\n",
        "        print()\n",
        "      elif not verbose and (t == len(loader_train)-1):\n",
        "        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n",
        "        acc = check_accuracy_part34(loader_val, model)\n",
        "        acc_history[e] = acc\n",
        "        iter_history[e] = tt\n",
        "        print()\n",
        "  return acc_history, iter_history"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGO2Vdz6doZs",
        "colab_type": "text"
      },
      "source": [
        "### Using the modular Api, training the two layered fully connected NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtaz0t4vdblV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "9177882c-60b6-4ef1-a892-e298e888ddef"
      },
      "source": [
        "fix_random_seed(0)\n",
        "\n",
        "C, H, W = 3, 32, 32\n",
        "num_classes = 10\n",
        "\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = TwoLayerFC(C*H*W, hidden_layer_size, num_classes)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                      weight_decay=weight_decay)\n",
        "\n",
        "_ = train_part345(model, optimizer)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Iteration 0, loss = 3.3988\n",
            "Checking accuracy on validation set\n",
            "Got 139 / 1000 correct (13.90)\n",
            "\n",
            "Epoch 0, Iteration 100, loss = 2.9726\n",
            "Checking accuracy on validation set\n",
            "Got 328 / 1000 correct (32.80)\n",
            "\n",
            "Epoch 0, Iteration 200, loss = 2.1085\n",
            "Checking accuracy on validation set\n",
            "Got 336 / 1000 correct (33.60)\n",
            "\n",
            "Epoch 0, Iteration 300, loss = 2.1709\n",
            "Checking accuracy on validation set\n",
            "Got 432 / 1000 correct (43.20)\n",
            "\n",
            "Epoch 0, Iteration 400, loss = 1.9805\n",
            "Checking accuracy on validation set\n",
            "Got 437 / 1000 correct (43.70)\n",
            "\n",
            "Epoch 0, Iteration 500, loss = 1.7867\n",
            "Checking accuracy on validation set\n",
            "Got 447 / 1000 correct (44.70)\n",
            "\n",
            "Epoch 0, Iteration 600, loss = 2.1035\n",
            "Checking accuracy on validation set\n",
            "Got 473 / 1000 correct (47.30)\n",
            "\n",
            "Epoch 0, Iteration 700, loss = 1.6729\n",
            "Checking accuracy on validation set\n",
            "Got 472 / 1000 correct (47.20)\n",
            "\n",
            "Epoch 0, Iteration 765, loss = 1.6794\n",
            "Checking accuracy on validation set\n",
            "Got 413 / 1000 correct (41.30)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTByz9cneDCa",
        "colab_type": "text"
      },
      "source": [
        "### Training three layered ConvNet:\n",
        "Using Modular Api on the Cifar-10 Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dKt2Di6dypZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "eac2cdf2-72cb-4e50-d3d3-b186ef0c294a"
      },
      "source": [
        "fix_random_seed(10)\n",
        "\n",
        "C = 3\n",
        "num_classes = 10\n",
        "\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "learning_rate = 3e-3\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model = ThreeLayerConvNet(C, channel_1, channel_2, num_classes)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "_ = train_part345(model, optimizer)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Iteration 0, loss = 3.2012\n",
            "Checking accuracy on validation set\n",
            "Got 123 / 1000 correct (12.30)\n",
            "\n",
            "Epoch 0, Iteration 100, loss = 1.6472\n",
            "Checking accuracy on validation set\n",
            "Got 360 / 1000 correct (36.00)\n",
            "\n",
            "Epoch 0, Iteration 200, loss = 1.5222\n",
            "Checking accuracy on validation set\n",
            "Got 428 / 1000 correct (42.80)\n",
            "\n",
            "Epoch 0, Iteration 300, loss = 1.4622\n",
            "Checking accuracy on validation set\n",
            "Got 452 / 1000 correct (45.20)\n",
            "\n",
            "Epoch 0, Iteration 400, loss = 1.6229\n",
            "Checking accuracy on validation set\n",
            "Got 468 / 1000 correct (46.80)\n",
            "\n",
            "Epoch 0, Iteration 500, loss = 1.4285\n",
            "Checking accuracy on validation set\n",
            "Got 494 / 1000 correct (49.40)\n",
            "\n",
            "Epoch 0, Iteration 600, loss = 1.3739\n",
            "Checking accuracy on validation set\n",
            "Got 483 / 1000 correct (48.30)\n",
            "\n",
            "Epoch 0, Iteration 700, loss = 1.4556\n",
            "Checking accuracy on validation set\n",
            "Got 488 / 1000 correct (48.80)\n",
            "\n",
            "Epoch 0, Iteration 765, loss = 1.3291\n",
            "Checking accuracy on validation set\n",
            "Got 506 / 1000 correct (50.60)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzuN4sXGDAvC",
        "colab_type": "text"
      },
      "source": [
        "### Using the Sequential API\n",
        "Two layered fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba59r1JhgWoc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "7f8d0dd7-c333-4a64-867d-0569cef1240d"
      },
      "source": [
        "fix_random_seed(0)\n",
        "\n",
        "C, H, W = 3, 32, 32\n",
        "num_classes = 10\n",
        "\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "momentum = 0.5\n",
        "\n",
        "# Using OrderedDict to give specific name to each module\n",
        "model = nn.Sequential(OrderedDict([\n",
        "    ('flatten', nn.Flatten()),\n",
        "    ('fc1', nn.Linear(C*H*W, hidden_layer_size)),\n",
        "    ('relu', nn.ReLU()),\n",
        "    ('fc2', nn.Linear(hidden_layer_size, num_classes))\n",
        "]))\n",
        "\n",
        "print('Architecture:')\n",
        "print(model) #printing to see the architecture of the module\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                      weight_decay=weight_decay,\n",
        "                      momentum=momentum, nesterov=True)\n",
        "\n",
        "_ = train_part345(model, optimizer)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:\n",
            "Sequential(\n",
            "  (flatten): Flatten()\n",
            "  (fc1): Linear(in_features=3072, out_features=4000, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=4000, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, Iteration 0, loss = 2.3772\n",
            "Checking accuracy on validation set\n",
            "Got 137 / 1000 correct (13.70)\n",
            "\n",
            "Epoch 0, Iteration 100, loss = 1.7474\n",
            "Checking accuracy on validation set\n",
            "Got 394 / 1000 correct (39.40)\n",
            "\n",
            "Epoch 0, Iteration 200, loss = 1.7006\n",
            "Checking accuracy on validation set\n",
            "Got 409 / 1000 correct (40.90)\n",
            "\n",
            "Epoch 0, Iteration 300, loss = 1.6135\n",
            "Checking accuracy on validation set\n",
            "Got 444 / 1000 correct (44.40)\n",
            "\n",
            "Epoch 0, Iteration 400, loss = 1.6331\n",
            "Checking accuracy on validation set\n",
            "Got 457 / 1000 correct (45.70)\n",
            "\n",
            "Epoch 0, Iteration 500, loss = 1.5453\n",
            "Checking accuracy on validation set\n",
            "Got 460 / 1000 correct (46.00)\n",
            "\n",
            "Epoch 0, Iteration 600, loss = 1.4802\n",
            "Checking accuracy on validation set\n",
            "Got 470 / 1000 correct (47.00)\n",
            "\n",
            "Epoch 0, Iteration 700, loss = 1.6623\n",
            "Checking accuracy on validation set\n",
            "Got 451 / 1000 correct (45.10)\n",
            "\n",
            "Epoch 0, Iteration 765, loss = 1.2971\n",
            "Checking accuracy on validation set\n",
            "Got 454 / 1000 correct (45.40)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ckyWs_EFqek",
        "colab_type": "text"
      },
      "source": [
        "### Using Sequential API \n",
        "Training a Three layered ConvNet\n",
        "1. Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2\n",
        "2. ReLU\n",
        "3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n",
        "4. ReLU\n",
        "5. Fully-connected layer (with bias) to compute scores for 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXAPEc0JGFhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "d7038c6e-f7dd-40f6-bf4b-b859076e85cc"
      },
      "source": [
        "fix_random_seed(0)\n",
        "\n",
        "C, H, W = 3, 32, 32\n",
        "num_classes = 10\n",
        "\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "kernel_size_1 = 5\n",
        "pad_size_1 = 2\n",
        "kernel_size_2 = 3\n",
        "pad_size_2 = 1\n",
        "\n",
        "learning_rate = 1e-2\n",
        "momentum = 0.5\n",
        "\n",
        "model = None \n",
        "optimizer = None \n",
        "\n",
        "model = nn.Sequential(OrderedDict([\n",
        "    ('conv1', nn.Conv2d(C, channel_1, kernel_size_1, padding=pad_size_1, bias=True)),\n",
        "    ('relu', nn.ReLU()),\n",
        "    ('conv2', nn.Conv2d(channel_1, channel_2, kernel_size_2, padding=pad_size_2, bias=True)),\n",
        "    ('relu', nn.ReLU()),\n",
        "    ('flatten', nn.Flatten()),\n",
        "    ('fc', nn.Linear(channel_2*H*W, num_classes, bias=True))\n",
        "]))\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=1e-4)\n",
        "\n",
        "print('Architecture:')\n",
        "print(model)\n",
        "\n",
        "_ = train_part345(model, optimizer)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:\n",
            "Sequential(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu): ReLU()\n",
            "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (flatten): Flatten()\n",
            "  (fc): Linear(in_features=16384, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, Iteration 0, loss = 2.3094\n",
            "Checking accuracy on validation set\n",
            "Got 168 / 1000 correct (16.80)\n",
            "\n",
            "Epoch 0, Iteration 100, loss = 1.6391\n",
            "Checking accuracy on validation set\n",
            "Got 430 / 1000 correct (43.00)\n",
            "\n",
            "Epoch 0, Iteration 200, loss = 1.3916\n",
            "Checking accuracy on validation set\n",
            "Got 465 / 1000 correct (46.50)\n",
            "\n",
            "Epoch 0, Iteration 300, loss = 1.8198\n",
            "Checking accuracy on validation set\n",
            "Got 490 / 1000 correct (49.00)\n",
            "\n",
            "Epoch 0, Iteration 400, loss = 1.5787\n",
            "Checking accuracy on validation set\n",
            "Got 536 / 1000 correct (53.60)\n",
            "\n",
            "Epoch 0, Iteration 500, loss = 1.4221\n",
            "Checking accuracy on validation set\n",
            "Got 502 / 1000 correct (50.20)\n",
            "\n",
            "Epoch 0, Iteration 600, loss = 1.4770\n",
            "Checking accuracy on validation set\n",
            "Got 549 / 1000 correct (54.90)\n",
            "\n",
            "Epoch 0, Iteration 700, loss = 1.3490\n",
            "Checking accuracy on validation set\n",
            "Got 554 / 1000 correct (55.40)\n",
            "\n",
            "Epoch 0, Iteration 765, loss = 1.3126\n",
            "Checking accuracy on validation set\n",
            "Got 565 / 1000 correct (56.50)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOplKBcd67Du",
        "colab_type": "text"
      },
      "source": [
        "##Plain block with \n",
        "1. Spatial Batch normalization\n",
        "2. ReLU\n",
        "3. Convolutional layer with `Cout` 3x3 filters, zero-padding of 1, and stride 2 if downsampling; otherwise stride 1\n",
        "4. Spatial Batch normalization\n",
        "5. ReLU\n",
        "6. Convolutional layer with `Cout` 3x3 filters, with zero-padding of 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw34dLBB66lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PlainBlock(nn.Module):\n",
        "    def __init__(self, Cin, Cout, downsample=False):\n",
        "        super().__init__()\n",
        "        stride = 2 if downsample else 1\n",
        "        self.net = nn.Sequential(\n",
        "            nn.BatchNorm2d(Cin),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(Cin, Cout, 3, stride=stride, padding=1),\n",
        "            nn.BatchNorm2d(Cout),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(Cout, Cout, 3, padding=1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GLIsG9n7KpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fa4fefaf-4476-4d43-d03e-57caf4487a54"
      },
      "source": [
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = PlainBlock(3, 10)\n",
        "if list(model(data).shape) == [2, 10, 5, 6]:\n",
        "  print('The output of PlainBlock without downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of PlainBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n",
        "\n",
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = PlainBlock(3, 10, downsample=True)\n",
        "if list(model(data).shape) == [2, 10, 3, 3]:\n",
        "  print('The output of PlainBlock with downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of PlainBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output of PlainBlock without downsampling has a *correct* dimension!\n",
            "The output of PlainBlock with downsampling has a *correct* dimension!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq6zYmRM7Pvf",
        "colab_type": "text"
      },
      "source": [
        "###Implementing a Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVwBS3it7M5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, Cin, Cout, downsample=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = None\n",
        "        self.shortcut = None\n",
        "\n",
        "        if not downsample:\n",
        "            if Cin == Cout:\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Identity()\n",
        "                )\n",
        "            else:\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Conv2d(Cin, Cout, 1)\n",
        "                )\n",
        "        else:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(Cin, Cout, 1, 2)\n",
        "            )\n",
        "        self.block = PlainBlock(Cin, Cout, downsample=downsample)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x) + self.shortcut(x)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-QfAspl7Swn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a334fc9-bc56-4013-bf8f-6af1dc0a7daf"
      },
      "source": [
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = ResidualBlock(3, 10)\n",
        "if list(model(data).shape) == [2, 10, 5, 6]:\n",
        "  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n",
        "\n",
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = ResidualBlock(3, 10, downsample=True)\n",
        "if list(model(data).shape) == [2, 10, 3, 3]:\n",
        "  print('The output of ResidualBlock with downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of ResidualBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output of ResidualBlock without downsampling has a *correct* dimension!\n",
            "The output of ResidualBlock with downsampling has a *correct* dimension!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfJsZnyQ7aVO",
        "colab_type": "text"
      },
      "source": [
        "###Residual Stage\n",
        "Stacking up the micro layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKggKita7VuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNetStage(nn.Module):\n",
        "    def __init__(self, Cin, Cout, num_blocks, downsample=True,\n",
        "                 block=ResidualBlock):\n",
        "        super().__init__()\n",
        "        blocks = [block(Cin, Cout, downsample)]\n",
        "        for _ in range(num_blocks -1):\n",
        "            blocks.append(block(Cout, Cout))\n",
        "        self.net = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "    "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y01wKSdJ7Zl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1ae9ba7-064b-4dfa-f41c-2069cda0af8f"
      },
      "source": [
        "print('Plain block stage:')\n",
        "print(ResNetStage(3, 4, 2, block=PlainBlock))\n",
        "print('Residual block stage:')\n",
        "print(ResNetStage(3, 4, 2, block=ResidualBlock))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plain block stage:\n",
            "ResNetStage(\n",
            "  (net): Sequential(\n",
            "    (0): PlainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (4): ReLU()\n",
            "        (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): PlainBlock(\n",
            "      (net): Sequential(\n",
            "        (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (4): ReLU()\n",
            "        (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Residual block stage:\n",
            "ResNetStage(\n",
            "  (net): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(3, 4, kernel_size=(1, 1), stride=(2, 2))\n",
            "      )\n",
            "      (block): PlainBlock(\n",
            "        (net): Sequential(\n",
            "          (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU()\n",
            "          (2): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU()\n",
            "          (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (shortcut): Sequential(\n",
            "        (0): Identity()\n",
            "      )\n",
            "      (block): PlainBlock(\n",
            "        (net): Sequential(\n",
            "          (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU()\n",
            "          (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU()\n",
            "          (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mdxd1gq7kLs",
        "colab_type": "text"
      },
      "source": [
        "###Residual Stem\n",
        "Stem layer is required at the beginning of the network, which increases the number of channel while keeping the other dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r0-NFpX7gV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNetStem(nn.Module):\n",
        "    def __init__(self, Cin=3, Cout=8):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            nn.Conv2d(Cin, Cout, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfPJJ2rR7nIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c4fbed3-3495-4b02-f1a0-ec40b8a7819b"
      },
      "source": [
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = ResNetStem(3, 10)\n",
        "if list(model(data).shape) == [2, 10, 5, 6]:\n",
        "  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output of ResidualBlock without downsampling has a *correct* dimension!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW5gzgZZ7rUI",
        "colab_type": "text"
      },
      "source": [
        "###Implementing ResNet using above blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RomZEy3z7qAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "networks = {\n",
        "  'plain32': {\n",
        "    'block': PlainBlock,\n",
        "    'stage_args': [\n",
        "      (8, 8, 5, False),\n",
        "      (8, 16, 5, True),\n",
        "      (16, 32, 5, True),\n",
        "    ]\n",
        "  },\n",
        "  'resnet32': {\n",
        "    'block': ResidualBlock,\n",
        "    'stage_args': [\n",
        "      (8, 8, 5, False),\n",
        "      (8, 16, 5, True),\n",
        "      (16, 32, 5, True),\n",
        "    ]\n",
        "  },\n",
        "}"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnU0albH75K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, stage_args, Cin=3, block=ResidualBlock, num_classes=10):\n",
        "    super().__init__()\n",
        "\n",
        "    self.cnn = None\n",
        "\n",
        "    blocks = [ResNetStem(Cin, stage_args[0][0])]\n",
        "    for arg in stage_args:\n",
        "      blocks.append(ResNetStage(*arg, block=block))\n",
        "    self.cnn = nn.Sequential(*blocks)\n",
        "    \n",
        "    self.fc = nn.Linear(stage_args[-1][1], num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    scores = None\n",
        "    # Replace \"pass\" statement with your code\n",
        "    out = self.cnn(x)\n",
        "    # print(out.shape)\n",
        "    pool = nn.AvgPool2d((out.shape[2], out.shape[3]))\n",
        "    out = pool(out)\n",
        "    # print(out.shape)\n",
        "    out = flatten(out)\n",
        "    # print(out.shape)\n",
        "    scores = self.fc(out)\n",
        "    \n",
        "    return scores\n",
        "\n",
        "def get_resnet(name):\n",
        "  return ResNet(**networks[name])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdS6b0PC78tW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9543b1e8-8754-4fa3-a814-7e7b9337b4d0"
      },
      "source": [
        "# def init_module(model):\n",
        "#   for m in model.modules():\n",
        "#     if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "#       nn.init.kaiming_normal_(m.weight.data)\n",
        "#       if m.bias is not None: nn.init.zeros_(m.bias.data)\n",
        "#     elif isinstance(m, nn.BatchNorm2d):\n",
        "#       nn.init.ones_(m.weight.data)\n",
        "#       if m.bias is not None: nn.init.zeros_(m.bias.data)\n",
        "\n",
        "names = ['plain32', 'resnet32']\n",
        "acc_history_dict = {}\n",
        "iter_history_dict = {}\n",
        "for name in names:\n",
        "  fix_random_seed(0)\n",
        "  print(name, '\\n')\n",
        "  model = get_resnet(name)\n",
        "#   init_module(model)\n",
        "  \n",
        "  optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=1e-4)\n",
        "\n",
        "  acc_history, iter_history = train_part345(model, optimizer, epochs=10, schedule=[6, 8], verbose=False)\n",
        "  acc_history_dict[name] = acc_history\n",
        "  iter_history_dict[name] = iter_history\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "plain32 \n",
            "\n",
            "Epoch 0, Iteration 765, loss = 1.5700\n",
            "Checking accuracy on validation set\n",
            "Got 426 / 1000 correct (42.60)\n",
            "\n",
            "Epoch 1, Iteration 1531, loss = 1.3946\n",
            "Checking accuracy on validation set\n",
            "Got 473 / 1000 correct (47.30)\n",
            "\n",
            "Epoch 2, Iteration 2297, loss = 1.2196\n",
            "Checking accuracy on validation set\n",
            "Got 531 / 1000 correct (53.10)\n",
            "\n",
            "Epoch 3, Iteration 3063, loss = 1.0853\n",
            "Checking accuracy on validation set\n",
            "Got 597 / 1000 correct (59.70)\n",
            "\n",
            "Epoch 4, Iteration 3829, loss = 1.2868\n",
            "Checking accuracy on validation set\n",
            "Got 606 / 1000 correct (60.60)\n",
            "\n",
            "Epoch 5, Iteration 4595, loss = 0.9604\n",
            "Checking accuracy on validation set\n",
            "Got 629 / 1000 correct (62.90)\n",
            "\n",
            "lr decay from 0.01 to 0.001\n",
            "Epoch 6, Iteration 5361, loss = 0.8811\n",
            "Checking accuracy on validation set\n",
            "Got 721 / 1000 correct (72.10)\n",
            "\n",
            "Epoch 7, Iteration 6127, loss = 0.6836\n",
            "Checking accuracy on validation set\n",
            "Got 716 / 1000 correct (71.60)\n",
            "\n",
            "lr decay from 0.001 to 0.0001\n",
            "Epoch 8, Iteration 6893, loss = 0.7124\n",
            "Checking accuracy on validation set\n",
            "Got 724 / 1000 correct (72.40)\n",
            "\n",
            "Epoch 9, Iteration 7659, loss = 0.9743\n",
            "Checking accuracy on validation set\n",
            "Got 718 / 1000 correct (71.80)\n",
            "\n",
            "resnet32 \n",
            "\n",
            "Epoch 0, Iteration 765, loss = 1.2119\n",
            "Checking accuracy on validation set\n",
            "Got 544 / 1000 correct (54.40)\n",
            "\n",
            "Epoch 1, Iteration 1531, loss = 1.2614\n",
            "Checking accuracy on validation set\n",
            "Got 569 / 1000 correct (56.90)\n",
            "\n",
            "Epoch 2, Iteration 2297, loss = 0.9723\n",
            "Checking accuracy on validation set\n",
            "Got 647 / 1000 correct (64.70)\n",
            "\n",
            "Epoch 3, Iteration 3063, loss = 0.6573\n",
            "Checking accuracy on validation set\n",
            "Got 722 / 1000 correct (72.20)\n",
            "\n",
            "Epoch 4, Iteration 3829, loss = 0.7160\n",
            "Checking accuracy on validation set\n",
            "Got 705 / 1000 correct (70.50)\n",
            "\n",
            "Epoch 5, Iteration 4595, loss = 0.6537\n",
            "Checking accuracy on validation set\n",
            "Got 758 / 1000 correct (75.80)\n",
            "\n",
            "lr decay from 0.01 to 0.001\n",
            "Epoch 6, Iteration 5361, loss = 0.4632\n",
            "Checking accuracy on validation set\n",
            "Got 804 / 1000 correct (80.40)\n",
            "\n",
            "Epoch 7, Iteration 6127, loss = 0.4072\n",
            "Checking accuracy on validation set\n",
            "Got 809 / 1000 correct (80.90)\n",
            "\n",
            "lr decay from 0.001 to 0.0001\n",
            "Epoch 8, Iteration 6893, loss = 0.5756\n",
            "Checking accuracy on validation set\n",
            "Got 802 / 1000 correct (80.20)\n",
            "\n",
            "Epoch 9, Iteration 7659, loss = 0.4487\n",
            "Checking accuracy on validation set\n",
            "Got 810 / 1000 correct (81.00)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrh1yVWc8htt",
        "colab_type": "text"
      },
      "source": [
        "####Plotting Validation accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3b-UMGd8Cve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "77f3cd0d-4078-4c5e-cf65-85f60aa330b9"
      },
      "source": [
        "plt.title('Val accuracies')\n",
        "for name in names:\n",
        "    plt.plot(iter_history_dict[name], acc_history_dict[name], '-o')\n",
        "plt.legend(names, loc='best')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('accurasy')\n",
        "plt.gcf().set_size_inches(9, 4)\n",
        "plt.show();"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk2X8HRiAclm",
        "colab_type": "text"
      },
      "source": [
        "###Resdidual BottleNeck block\n",
        "1. Spatial Batch normalization\n",
        "2. ReLU\n",
        "3. Convolutional layer with `Cout // 4` 1x1 filters, stride 2 if downsampling; otherwise stride 1\n",
        "4. Spatial Batch normalization\n",
        "5. ReLU\n",
        "6. Convolutional layer with `Cout // 4` 3x3 filters, with zero-padding of 1\n",
        "7. Spatial Batch normalization\n",
        "8. ReLU\n",
        "9. Convolutional layer with `Cout` 1x1 filters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBc6Q3zB99k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBottleneckBlock(nn.Module):\n",
        "    def __init__(self, Cin, Cout, downsample=False):\n",
        "        super().__init__()\n",
        "\n",
        "        stride = 2 if downsample else 1\n",
        "        self.block = nn.Sequential(\n",
        "            nn.BatchNorm2d(Cin),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(Cin, Cout // 4, 1, stride=stride),\n",
        "            nn.BatchNorm2d(Cout // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(Cout//4, Cout // 4, 3, padding=1),\n",
        "            nn.BatchNorm2d(Cout // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(Cout//4, Cout, 1)\n",
        "        )\n",
        "        if not downsample:\n",
        "            if Cin == Cout:\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Identity()\n",
        "                )\n",
        "            else:\n",
        "                self.shortcut = nn.Sequential(\n",
        "                    nn.Conv2d(Cin, Cout, 1)\n",
        "                )\n",
        "        else:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(Cin, Cout, 1, stride = 2)\n",
        "                )\n",
        "    def forward(self, x):\n",
        "        return self.block(x) + self.shortcut(x)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzuxZ1_D-ftv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fe0985bd-d4e0-42d0-fd0e-1d0b7d5028a5"
      },
      "source": [
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = ResidualBottleneckBlock(3, 10)\n",
        "if list(model(data).shape) == [2, 10, 5, 6]:\n",
        "  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n",
        "\n",
        "data = torch.zeros(2, 3, 5, 6)\n",
        "model = ResidualBottleneckBlock(3, 10, downsample=True)\n",
        "if list(model(data).shape) == [2, 10, 3, 3]:\n",
        "  print('The output of ResidualBlock with downsampling has a *correct* dimension!')\n",
        "else:\n",
        "  print('The output of ResidualBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output of ResidualBlock without downsampling has a *correct* dimension!\n",
            "The output of ResidualBlock with downsampling has a *correct* dimension!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZz-_rKDHqQg",
        "colab_type": "text"
      },
      "source": [
        "### Checking architecture of ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q52qDXzsG41s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34d3b039-7a0d-4f04-fdb5-8dd4857fe9e4"
      },
      "source": [
        "# example of specification\n",
        "networks.update({\n",
        "  'resnet47': {\n",
        "    'block': ResidualBottleneckBlock,\n",
        "    'stage_args': [\n",
        "      (32, 32, 5, False),\n",
        "      (32, 64, 5, True),\n",
        "      (64, 128, 5, True),\n",
        "    ],\n",
        "  },\n",
        "})\n",
        "\n",
        "print(get_resnet('resnet47'))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (cnn): Sequential(\n",
            "    (0): ResNetStem(\n",
            "      (net): Sequential(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNetStage(\n",
            "      (net): Sequential(\n",
            "        (0): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (1): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (2): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (3): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (4): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): ResNetStage(\n",
            "      (net): Sequential(\n",
            "        (0): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(32, 16, kernel_size=(1, 1), stride=(2, 2))\n",
            "            (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
            "          )\n",
            "        )\n",
            "        (1): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (2): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (3): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (4): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): ResNetStage(\n",
            "      (net): Sequential(\n",
            "        (0): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2))\n",
            "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "          )\n",
            "        )\n",
            "        (1): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (2): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (3): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "        (4): ResidualBottleneckBlock(\n",
            "          (block): Sequential(\n",
            "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (1): ReLU()\n",
            "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (4): ReLU()\n",
            "            (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (7): ReLU()\n",
            "            (8): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (shortcut): Sequential(\n",
            "            (0): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}